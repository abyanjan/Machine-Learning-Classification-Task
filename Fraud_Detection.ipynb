{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fraud Detection\n",
    "\n",
    "#### Detecting Fradulent Credit Card transactions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Dataset/creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abyanjan.FSE17-32\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: `Series.plot()` should not be called with positional arguments, only keyword arguments. The order of positional arguments will change in the future. Use `Series.plot(kind='bar')` instead of `Series.plot('bar',)`.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1cd63b9de80>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Target distribution\n",
    "data.Class.value_counts().plot('bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    99.827251\n",
       "1     0.172749\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Class.value_counts(normalize = True)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only around 0.17% of the transactions ara fradulent, therefore we have highly imbalance data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing\n",
    "\n",
    "All the features have been standardised except for the Amount column, so we will need to standardised it to bring it into the dame range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data['normalized_Amount'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the original Amount column and Time column\n",
    "data.drop(['Amount', 'Time'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "      <th>normalized_Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "      <td>0.244964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.342475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "      <td>1.160686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "      <td>0.140534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.073403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10  ...       V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  0.090794  ... -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425 -0.166974  ... -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  0.207643  ...  0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024 -0.054952  ... -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  0.753074  ... -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Class  normalized_Amount  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053      0           0.244964  \n",
       "1  0.167170  0.125895 -0.008983  0.014724      0          -0.342475  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752      0           1.160686  \n",
       "3  0.647376 -0.221929  0.062723  0.061458      0           0.140534  \n",
       "4 -0.206010  0.502292  0.219422  0.215153      0          -0.073403  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#input features\n",
    "X = data.drop('Class', axis = 1)\n",
    "\n",
    "# target\n",
    "y = data['Class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((199364, 29), (85443, 29))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting to arrays\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 16)                480       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 24)                408       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 20)                500       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 24)                504       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 25        \n",
      "=================================================================\n",
      "Total params: 1,917\n",
      "Trainable params: 1,917\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units = 16, input_dim= 29, activation = 'relu'))\n",
    "model.add(Dense(units =24, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units =20 , activation = 'relu'))\n",
    "model.add(Dense(units =24, activation = 'relu'))\n",
    "\n",
    "model.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 199364 samples\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:From C:\\Users\\abyanjan.FSE17-32\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000001CD6DF268C8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000001CD6DF268C8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "199364/199364 [==============================] - 54s 272us/sample - loss: 0.0088 - accuracy: 0.9988\n",
      "Epoch 2/5\n",
      "199364/199364 [==============================] - 54s 271us/sample - loss: 0.0040 - accuracy: 0.9992\n",
      "Epoch 3/5\n",
      "199364/199364 [==============================] - 54s 272us/sample - loss: 0.0037 - accuracy: 0.9994\n",
      "Epoch 4/5\n",
      "199364/199364 [==============================] - 53s 267us/sample - loss: 0.0034 - accuracy: 0.9993\n",
      "Epoch 5/5\n",
      "199364/199364 [==============================] - 53s 268us/sample - loss: 0.0031 - accuracy: 0.9993\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1cd6df3e470>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compile the model\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# fit the model\n",
    "model.fit(X_train, y_train, epochs = 5, batch_size = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.9994\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "#score = model.evaluate(X_test, y_test)\n",
    "pred_test = model.predict_classes(X_test)\n",
    "\n",
    "# Accuracy\n",
    "score = accuracy_score(y_test, pred_test)\n",
    "print(f'Accuracy on test set: {round(score,4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[85272    24]\n",
      " [   28   119]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "conf_mat = confusion_matrix(y_test, pred_test)\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the confusion matrix, we can see that the model was able to identify almost all the non fradulent transactions corretly, only missing 24 of them. For the fradulent class it misclassified 28 out of total 147. Since, the fraudlent cases are more expensive, we would like to make more mistakes on classifying them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auc Score: 0.965\n"
     ]
    }
   ],
   "source": [
    "# AUC score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "pred_test_prob = model.predict(X_test)\n",
    "\n",
    "auc_score = roc_auc_score(y_test, pred_test_prob)\n",
    "\n",
    "print(f'Auc Score: {round(auc_score,3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "Rf_model = RandomForestClassifier(n_estimators=100)\n",
    "Rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test set\n",
    "y_pred_class = Rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[85289     7]\n",
      " [   33   114]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is not doing any better than the Deep Neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score: 0.9370421705542094\n"
     ]
    }
   ],
   "source": [
    "# Auc score\n",
    "y_pred = Rf_model.predict_proba(X_test)[:,1]\n",
    "print(f'AUC score: {roc_auc_score(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "492\n"
     ]
    }
   ],
   "source": [
    "# fradulent transactions\n",
    "fraud_indices = np.array(data[data.Class == 1].index)\n",
    "num_fraud_records = len(fraud_indices)\n",
    "print(num_fraud_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "284315\n"
     ]
    }
   ],
   "source": [
    "# non fradulent trainsactions\n",
    "non_fraud_indices =np.array(data[data.Class == 0].index)\n",
    "num_non_fraud_records = len(non_fraud_indices)\n",
    "print(num_non_fraud_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "492\n"
     ]
    }
   ],
   "source": [
    "# taking random sample of non fraudlent data to match the number of fraudulent records\n",
    "random_samples = np.random.choice(non_fraud_indices, num_fraud_records, replace = False)\n",
    "random_samples = np.array(random_samples)\n",
    "print(len(random_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "984\n"
     ]
    }
   ],
   "source": [
    "# concatenate the random non fradulent samples with fraudlent records\n",
    "undersample_indices = np.concatenate([fraud_indices, random_samples])\n",
    "print(len(undersample_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "undersample_df = data.iloc[undersample_indices,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_under = undersample_df.drop('Class', axis = 1)\n",
    "y_under = undersample_df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_under, y_under, test_size =0.3 , random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 16)                480       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 24)                408       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 20)                500       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 24)                504       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 25        \n",
      "=================================================================\n",
      "Total params: 1,917\n",
      "Trainable params: 1,917\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Deep learning\n",
    "model = Sequential()\n",
    "model.add(Dense(units = 16, input_dim= 29, activation = 'relu'))\n",
    "model.add(Dense(units =24, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units =20 , activation = 'relu'))\n",
    "model.add(Dense(units =24, activation = 'relu'))\n",
    "\n",
    "model.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 688 samples\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000001CD04248158> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000001CD04248158> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "688/688 [==============================] - 1s 2ms/sample - loss: 0.2444 - accuracy: 0.9244\n",
      "Epoch 2/5\n",
      "688/688 [==============================] - 0s 212us/sample - loss: 0.2226 - accuracy: 0.9157\n",
      "Epoch 3/5\n",
      "688/688 [==============================] - 0s 227us/sample - loss: 0.1900 - accuracy: 0.9331\n",
      "Epoch 4/5\n",
      "688/688 [==============================] - 0s 250us/sample - loss: 0.1757 - accuracy: 0.9346\n",
      "Epoch 5/5\n",
      "688/688 [==============================] - 0s 211us/sample - loss: 0.1831 - accuracy: 0.9419\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1cd091cce48>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compile the model\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# fit the model\n",
    "model.fit(X_train, y_train, epochs = 5, batch_size = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[144   5]\n",
      " [ 15 132]]\n"
     ]
    }
   ],
   "source": [
    "# prediction\n",
    "y_pred_class = model.predict_classes(X_test)\n",
    "\n",
    "# confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9324324324324325\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "print(accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9828334018171027\n"
     ]
    }
   ],
   "source": [
    "# Auc\n",
    "y_pred = model.predict(X_test)\n",
    "print(roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see we have much better auc score then before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_resample, y_resample = SMOTE().fit_sample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_resample, y_resample, test_size = 0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 398041 samples\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000001CD0609BD90> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000001CD0609BD90> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "398041/398041 [==============================] - 92s 231us/sample - loss: 0.0427 - accuracy: 0.9851\n",
      "Epoch 2/5\n",
      "398041/398041 [==============================] - 89s 225us/sample - loss: 0.0175 - accuracy: 0.9953\n",
      "Epoch 3/5\n",
      "398041/398041 [==============================] - 90s 226us/sample - loss: 0.0143 - accuracy: 0.9962\n",
      "Epoch 4/5\n",
      "398041/398041 [==============================] - 90s 227us/sample - loss: 0.0119 - accuracy: 0.9969\n",
      "Epoch 5/5\n",
      "398041/398041 [==============================] - 89s 223us/sample - loss: 0.0107 - accuracy: 0.9973\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1cd6a7e6ba8>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compile the model\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# fit the model\n",
    "model.fit(X_train, y_train, epochs = 5, batch_size = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[84887   285]\n",
      " [   44 85373]]\n"
     ]
    }
   ],
   "source": [
    "# prediction\n",
    "y_pred_class = model.predict_classes(X_test)\n",
    "\n",
    "# confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.998071387955847\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "print(accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9997849596427737\n"
     ]
    }
   ],
   "source": [
    "# Auc\n",
    "y_pred = model.predict(X_test)\n",
    "print(roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With SMOTE oversampling we have the best AUC score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
